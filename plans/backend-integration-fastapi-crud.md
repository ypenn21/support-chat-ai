# Feature Implementation Plan: Backend Integration with FastAPI + Google ADK (Simplified)

## üìã Todo Checklist
- [x] Set up backend development environment and dependencies
- [x] Install and configure Google ADK (Agent Development Kit)
- [x] Design simplified single-agent architecture for both modes
- [x] Implement unified agent service with Gemini 2.5 Flash
- [x] Create CRUD API endpoints (Suggestion + Autonomous modes)
- [x] Implement conversation logging and analytics
- [x] Test backend endpoints locally (all passing ‚úì)
- [ ] Add authentication and rate limiting middleware
- [ ] Replace mock API client with real API calls in extension
- [ ] Implement actual ADK agent.run() calls (currently placeholders)
- [ ] Deploy unified service to Google Cloud Run
- [ ] Configure GCP services (Vertex AI, Secret Manager, Firestore)
- [ ] End-to-end testing with extension
- [ ] Final Review and Testing

## ‚úÖ Implementation Progress

### **Completed (2025-11-04)**

#### **Phase 0 & 1: Core Backend with ADK - COMPLETE ‚úì**

**Environment Setup:**
- ‚úÖ Python virtual environment created
- ‚úÖ Google ADK installed (`google-adk` + dependencies)
- ‚úÖ Environment variables configured in `.env` file
- ‚úÖ Project structure created (`app/agents/`, `app/agents/tools/`, `app/api/routes/`)

**ADK Tool Functions Implemented:**
- ‚úÖ `app/agents/tools/context_tools.py` - `process_conversation_context()`
  - Validates message count (1-50)
  - Extracts entities (order numbers, emails)
  - Detects conversation intent
- ‚úÖ `app/agents/tools/goal_tools.py` - `track_goal_progress()`
  - Increments turn counter
  - Calculates progress percentage
  - Returns updated goal state
- ‚úÖ `app/agents/tools/safety_tools.py` - `check_safety_constraints()`
  - Checks escalation keywords
  - Validates confidence thresholds
  - Detects confusion patterns

**Agent Services Implemented:**
- ‚úÖ `app/agents/suggestion_agent.py` - `SuggestionAgentService`
  - Single agent with Gemini 2.5 Flash
  - Tools: process_conversation_context
  - Returns Suggestion with confidence score
  - **Note**: Uses placeholder responses (TODO: actual ADK agent.run() call)

- ‚úÖ `app/agents/autonomous_agent.py` - `AutonomousAgentService`
  - Single agent with Gemini 2.5 Flash
  - Tools: track_goal_progress, check_safety_constraints
  - Returns AutonomousResponse with action decision
  - **Note**: Uses placeholder responses (TODO: actual ADK agent.run() call)

- ‚úÖ `app/services/agent_service.py` - `AgentService`
  - Unified coordination layer for both agents
  - Initializes agents with GCP project settings

**Pydantic Models Updated:**
- ‚úÖ `app/models/request.py` - Added models:
  - `Goal` - YOLO mode goal definition
  - `GoalState` - Current goal progress state
  - `SafetyConstraints` - Autonomous mode safety rules
  - `AutonomousRequest` - Complete autonomous request model
  - Updated `SuggestRequest` with request_id field

- ‚úÖ `app/models/response.py` - Updated models:
  - `Suggestion` - Changed `id`/`content` to `text` field
  - `Metadata` - Updated fields (request_id, processing_time_ms, timestamp)
  - `AutonomousResponse` - New model for YOLO mode responses

#### **Phase 2: API Endpoints - COMPLETE ‚úì**

**Endpoints Implemented:**
- ‚úÖ `app/api/routes/suggest.py` - POST `/api/suggest-response`
  - Accepts SuggestRequest
  - Calls SuggestionAgent via AgentService
  - Returns SuggestResponse with metadata
  - **Test Result**: 200 OK ‚úì

- ‚úÖ `app/api/routes/autonomous.py` - POST `/api/autonomous-response`
  - Accepts AutonomousRequest
  - Validates goal, goal_state, safety_constraints
  - Checks turn limits
  - Calls AutonomousAgent via AgentService
  - **Test Result**: 200 OK ‚úì

- ‚úÖ `app/api/routes/feedback.py` - POST `/api/feedback`
  - Accepts FeedbackRequest (rating, feedback_text, suggestion_used)
  - Logs feedback (TODO: persist to Firestore)
  - Returns feedback_id and status
  - **Test Result**: 200 OK ‚úì

- ‚úÖ `app/api/routes/conversation_logs.py` - Two endpoints:
  - POST `/api/conversation-logs` - Save conversation log
  - GET `/api/conversation-logs` - Retrieve logs with filters
  - In-memory storage for testing (TODO: replace with Firestore)
  - **Test Results**: Both 200 OK ‚úì

**FastAPI Application:**
- ‚úÖ All routes registered in `app/main.py`
- ‚úÖ CORS middleware configured
- ‚úÖ Health endpoint working
- ‚úÖ Swagger docs available at `/docs`

**Testing:**
- ‚úÖ Local server tested on port 8001
- ‚úÖ Test scripts created: `test_api.py`, `test_autonomous_api.py`
- ‚úÖ All endpoints return 200 OK
- ‚úÖ Response models match expected structure

**Test Results Summary:**
```
‚úì GET /health - Status: healthy
‚úì GET / - Message with API info
‚úì POST /api/suggest-response - Returns suggestions
‚úì POST /api/autonomous-response - Returns action decision
‚úì POST /api/feedback - Records feedback
‚úì POST /api/conversation-logs - Saves log
‚úì GET /api/conversation-logs - Retrieves logs with pagination
```

### **Remaining Work**

#### **Phase 2: Complete ADK Integration**
- [ ] Replace placeholder responses with actual `agent.run()` calls
- [ ] Test actual Vertex AI API integration
- [ ] Handle ADK tool invocation responses
- [ ] Add error handling for ADK failures

#### **Phase 3: Security & Infrastructure (1-2 hours)**
- [ ] Implement API key authentication middleware
- [ ] Add SlowAPI rate limiting (60 req/min)
- [ ] Replace in-memory storage with Firestore
- [ ] Add Secret Manager integration for API keys
- [ ] Set up Cloud Logging

#### **Phase 4: Extension Integration (1-2 hours)**
- [ ] Replace mock API in `extension/src/background/api-client.ts`
- [ ] Add Cloud Run URL to extension environment config
- [ ] Update TypeScript types to match updated Pydantic models
- [ ] Test extension with real backend

#### **Phase 5: Deployment (1-2 hours)**
- [ ] Build and push Docker image to Artifact Registry
- [ ] Deploy unified service to Cloud Run
- [ ] Configure production environment variables
- [ ] Set up Cloud Run service with min/max instances
- [ ] Get production URL and update extension

#### **Phase 6: Testing & Validation (2-3 hours)**
- [ ] Write pytest unit tests for agents and tools
- [ ] Write integration tests for API endpoints
- [ ] Validate OpenAPI spec compliance
- [ ] End-to-end testing with extension
- [ ] Performance testing (latency < 2s target)
- [ ] Load testing with multiple concurrent requests

**Important Notes:**
1. All agents currently use placeholder responses - actual ADK `agent.run()` calls need implementation
2. Conversation logs use in-memory storage - needs Firestore integration for production
3. No authentication/rate limiting yet - required for production deployment
4. Local testing successful - ready for GCP deployment after completing remaining tasks

## üîç Analysis & Investigation

### Simplified Architecture Overview

**Key Simplifications:**
1. **Single Model**: Gemini 2.5 Flash for ALL operations (Suggestion + YOLO modes)
2. **Single Agent per Mode**: No multi-agent orchestration complexity
3. **Unified Service**: FastAPI + ADK agents deployed together in one Cloud Run service
4. **No Agent Engine**: Direct Cloud Run deployment only

**Why This Approach?**
- **Cost-Effective**: Gemini 2.5 Flash is significantly cheaper than Pro
- **Simpler**: Single agent per mode reduces complexity and debugging difficulty
- **Faster**: Less orchestration overhead, quicker responses
- **Easier Deployment**: One service, one deployment, simpler monitoring
- **Good Enough**: Flash model is sufficient for support chat suggestions and safety checks

**Simplified ADK Architecture:**
```
Support Chat Extension
    ‚Üì HTTP POST
Cloud Run Service (Single Deployment)
‚îú‚îÄ‚îÄ FastAPI Layer (Routes + Middleware)
‚îî‚îÄ‚îÄ ADK Agents (Same Process)
    ‚îú‚îÄ‚îÄ SuggestionAgent
    ‚îÇ   ‚îú‚îÄ‚îÄ Model: Gemini 2.5 Flash
    ‚îÇ   ‚îú‚îÄ‚îÄ Tools: process_conversation_context()
    ‚îÇ   ‚îî‚îÄ‚îÄ Output: Suggestion with confidence
    ‚îî‚îÄ‚îÄ AutonomousAgent
        ‚îú‚îÄ‚îÄ Model: Gemini 2.5 Flash (NOT multi-agent)
        ‚îú‚îÄ‚îÄ Tools: track_goal(), check_safety()
        ‚îî‚îÄ‚îÄ Output: Action decision + response

Vertex AI Gemini 2.5 Flash (single model)
```

### API Specification

**OpenAPI Specification:**
- ‚úÖ **Complete OpenAPI 3.0 spec created**: `docs/api-spec.yaml` (919 lines)
- ‚úÖ **All endpoints defined**: health, suggest-response, autonomous-response, feedback, conversation-logs
- ‚úÖ **Request/Response models**: Full Pydantic-compatible schema definitions
- ‚úÖ **Examples included**: Request/response examples for all endpoints
- ‚úÖ **Error responses**: 400, 401, 429, 500, 503 error schemas
- ‚úÖ **Security definitions**: API key authentication via X-API-Key header

**Key Endpoints from Spec:**
1. `GET /health` - Health check (no auth)
2. `POST /api/suggest-response` - Suggestion Mode (SuggestRequest ‚Üí SuggestResponse)
3. `POST /api/autonomous-response` - YOLO Mode (AutonomousRequest ‚Üí AutonomousResponse)
4. `POST /api/feedback` - Feedback submission (FeedbackRequest ‚Üí success)
5. `GET /api/conversation-logs` - Retrieve logs (query params ‚Üí ConversationLogMetadata[])
6. `POST /api/conversation-logs` - Save logs (ConversationLogCreate ‚Üí success)

**Schema Reference:**
All implementation must match schemas defined in `docs/api-spec.yaml`:
- Request models: Message, UserPreferences, SuggestRequest, Goal, GoalState, SafetyConstraints, AutonomousRequest, FeedbackRequest, ConversationLogCreate
- Response models: Suggestion, Metadata, SuggestResponse, AutonomousResponse, ConversationLogMetadata, Error

### Codebase Structure

**Backend Status:**
The FastAPI backend skeleton exists at `/backend` with the following structure:
- ‚úÖ Project structure defined (`app/api/routes/`, `app/services/`, `app/models/`, `app/core/`)
- ‚úÖ Pydantic models created (`request.py`, `response.py`)
- ‚úÖ Configuration management with `pydantic-settings`
- ‚úÖ Main FastAPI app initialized with CORS and health check
- ‚úÖ **OpenAPI specification complete** (`docs/api-spec.yaml`)
- ‚ùå **Google ADK NOT installed** (will be added to requirements.txt)
- ‚ùå **ADK agents NOT implemented** (new: `app/agents/` directory)
- ‚ùå **API routes NOT implemented** (only TODO comments exist)
- ‚ùå **Services NOT implemented** (directories empty)

**Extension Status:**
- ‚úÖ Extension fully built with mock API
- ‚úÖ Background service worker with API client (`background/api-client.ts`)
- ‚úÖ TypeScript types matching backend Pydantic models
- ‚úÖ Currently using `mock-api.ts` for all API calls
- üîÑ Ready to replace mock with real API calls

### Current Architecture

**Technology Stack:**
- **Backend**: FastAPI 0.109.0, Python 3.11+, Uvicorn, Gunicorn
- **AI Framework**: Google ADK (Agent Development Kit) - Simplified single-agent approach
- **AI Model**: **Gemini 2.5 Flash ONLY** - Cost-effective and fast
- **Validation**: Pydantic 2.5.0
- **GCP Services**: Vertex AI, Secret Manager, Firestore, Cloud Logging
- **Deployment**: **Single Cloud Run service** (no Agent Engine)
- **Extension**: TypeScript, Chrome Manifest V3
- **API Documentation**: OpenAPI 3.0.3

**Simplified Backend Structure:**
```
backend/app/
‚îú‚îÄ‚îÄ main.py                   # FastAPI app + ADK agent initialization (unified)
‚îú‚îÄ‚îÄ agents/                   # ADK agents (simplified)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ suggestion_agent.py   # Single SuggestionAgent with Gemini 2.5 Flash
‚îÇ   ‚îú‚îÄ‚îÄ autonomous_agent.py   # Single AutonomousAgent with Gemini 2.5 Flash
‚îÇ   ‚îî‚îÄ‚îÄ tools/                # ADK tool functions (Python functions)
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ context_tools.py  # process_conversation_context()
‚îÇ       ‚îú‚îÄ‚îÄ goal_tools.py     # track_goal_progress()
‚îÇ       ‚îî‚îÄ‚îÄ safety_tools.py   # check_safety_constraints()
‚îú‚îÄ‚îÄ api/routes/               # API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ suggest.py            # POST /api/suggest-response
‚îÇ   ‚îú‚îÄ‚îÄ autonomous.py         # POST /api/autonomous-response
‚îÇ   ‚îú‚îÄ‚îÄ feedback.py           # POST /api/feedback
‚îÇ   ‚îî‚îÄ‚îÄ logs.py               # GET/POST /api/conversation-logs
‚îú‚îÄ‚îÄ services/                 # Business logic (thin layer)
‚îÇ   ‚îî‚îÄ‚îÄ agent_service.py      # Coordinates agents (no separate gemini.py)
‚îú‚îÄ‚îÄ models/                   # Data models (‚úÖ complete)
‚îÇ   ‚îú‚îÄ‚îÄ request.py            # SuggestRequest, Message, UserPreferences
‚îÇ   ‚îî‚îÄ‚îÄ response.py           # SuggestResponse, Suggestion, Metadata
‚îî‚îÄ‚îÄ core/                     # Core utilities
    ‚îú‚îÄ‚îÄ config.py             # Settings management
    ‚îú‚îÄ‚îÄ security.py           # Auth & rate limiting
    ‚îî‚îÄ‚îÄ database.py           # Firestore client
```

**Key Simplifications:**
- ‚ùå No multi-agent orchestration - each mode uses ONE agent
- ‚ùå No separate service layers - agents called directly from routes
- ‚ùå No Agent Engine deployment - Cloud Run only
- ‚úÖ All agents use Gemini 2.5 Flash (cost-effective)
- ‚úÖ FastAPI + ADK in same process (no separation)

### Dependencies & Integration Points

**Required GCP Services:**
1. **Vertex AI** - Gemini 2.5 Flash for response generation (via ADK)
2. **Secret Manager** - Store API keys securely
3. **Firestore** - Store conversation logs and analytics
4. **Cloud Logging** - Application logs
5. **Artifact Registry** - Docker image storage
6. **Cloud Run** - Serverless deployment (unified service)

**Integration Flow (Simplified):**
```
Extension (Content Script)
    ‚Üì chrome.runtime.sendMessage()
Background Service Worker (api-client.ts)
    ‚Üì HTTP POST (fetch/axios)
Cloud Run Service (FastAPI + ADK in same process)
    ‚Üì Route ‚Üí Agent (direct call, no layering)
ADK Agent (SuggestionAgent OR AutonomousAgent)
    ‚Üì LLM call with tools
Vertex AI Gemini 2.5 Flash
    ‚Üì response
ADK Agent (post-processing)
    ‚Üì structured output
FastAPI Route
    ‚Üì JSON response (per OpenAPI spec)
Extension (displays suggestion)
```

**Environment Variables Required:**
```bash
# GCP Configuration
GCP_PROJECT_ID=your-project-id
GCP_REGION=us-central1
VERTEX_AI_LOCATION=us-central1

# Model Configuration (SIMPLIFIED)
GEMINI_MODEL=gemini-2.5-flash  # Single model for everything

# ADK Configuration
ADK_ENABLE_TRACING=true  # for debugging
ADK_LOG_LEVEL=INFO

# Security
API_KEY_SECRET_NAME=support-chat-ai-api-key

# Storage
FIRESTORE_COLLECTION=suggestions

# CORS (Chrome Extension ID)
ALLOWED_ORIGINS=chrome-extension://YOUR_EXTENSION_ID

# Rate Limiting
RATE_LIMIT_PER_MINUTE=60

# Environment
ENVIRONMENT=production
DEBUG=false
```

### Considerations & Challenges

**1. Single Model Strategy**
- **Challenge**: Using only Gemini 2.5 Flash for everything
- **Solution**: Flash is fast and cost-effective, sufficient for support chat
- **Benefit**: Simpler configuration, lower costs, consistent performance

**2. No Multi-Agent Complexity**
- **Challenge**: YOLO mode safety without multi-agent orchestration
- **Solution**: Single agent with multiple tool calls in sequence
- **Benefit**: Easier to debug, faster responses, simpler deployment

**3. Unified Service Deployment**
- **Challenge**: FastAPI + ADK in same process
- **Solution**: Initialize agents on app startup, reuse across requests
- **Benefit**: No network overhead, simpler architecture, easier monitoring

**4. Cost Optimization**
- **Challenge**: Keep costs low
- **Solution**:
  - Gemini 2.5 Flash is 10x cheaper than Pro
  - Single model = predictable costs
  - Cloud Run auto-scaling prevents waste
  - Response caching for common queries

**5. Latency Requirements**
- **Challenge**: Users expect <2 second responses
- **Solution**:
  - Flash model is faster than Pro
  - No multi-agent overhead
  - Cloud Run min instances = 1 (avoid cold starts)
  - Monitor P95 latency

**6. YOLO Mode Safety (Simplified)**
- **Challenge**: Autonomous responses require safety checks
- **Solution**:
  - Single agent with `check_safety()` and `track_goal()` tools
  - Agent calls tools sequentially: analyze ‚Üí check_safety ‚Üí respond/escalate
  - All safety logic in tools (testable and reusable)
  - Confidence threshold checks (min 0.7 per OpenAPI spec)

## üìù Implementation Plan

### Prerequisites

1. **GCP Project Setup**
   ```bash
   # Create GCP project (if not exists)
   gcloud projects create support-chat-ai --name="Support Chat AI"
   gcloud config set project support-chat-ai

   # Enable required APIs
   gcloud services enable aiplatform.googleapis.com
   gcloud services enable secretmanager.googleapis.com
   gcloud services enable firestore.googleapis.com
   gcloud services enable run.googleapis.com
   gcloud services enable artifactregistry.googleapis.com

   # Create Artifact Registry repository
   gcloud artifacts repositories create support-chat-ai \
     --repository-format=docker \
     --location=us-central1
   ```

2. **Local Development Setup**
   ```bash
   cd backend
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   pip install -r requirements.txt
   pip install -r requirements-dev.txt

   # Authenticate with GCP
   gcloud auth application-default login

   # Copy environment template
   cp .env.example .env
   # Edit .env with your GCP_PROJECT_ID
   ```

3. **Install Google ADK and Additional Dependencies**
   ```bash
   pip install google-adk  # Google Agent Development Kit
   pip install slowapi  # Rate limiting
   pip install google-cloud-firestore  # Firestore
   pip install google-cloud-secret-manager  # Secret Manager
   ```

### Step-by-Step Implementation

#### **Phase 0: ADK Setup & Architecture Design (30 mins - SIMPLIFIED) - ‚úÖ COMPLETE**

**‚ö†Ô∏è SIMPLIFIED ARCHITECTURE**
This plan uses a simplified single-agent approach:
- ‚úÖ Single Model: Gemini 2.5 Flash for ALL operations
- ‚úÖ Single Agent per Mode: No multi-agent orchestration
- ‚úÖ Unified Service: FastAPI + ADK in one Cloud Run deployment
- ‚úÖ Correct ADK API: `from google.adk.agents import Agent`

**Step 0.1: Install and Configure Google ADK** - ‚úÖ COMPLETE
- Files modified: `backend/requirements.txt`
- Changes made:
  ```txt
  # Added to requirements.txt
  google-adk  # Agent Development Kit
  slowapi     # Rate limiting
  ```
- Installation: ‚úÖ Successfully installed with pip
- Verification: ‚úÖ Confirmed working: `from google.adk.agents import Agent`
- Environment: ‚úÖ `.env` file created with GCP configuration

**Step 0.2: Design Simplified Agent Architecture** - ‚úÖ COMPLETE
- **Reference**: ADK documentation, OpenAPI spec requirements
- **Agent Design** (IMPLEMENTED):

  **SuggestionAgent (Suggestion Mode)**:
  ```python
  SuggestionAgent (Single Agent)
  ‚îú‚îÄ‚îÄ Model: Gemini 2.5 Flash
  ‚îú‚îÄ‚îÄ Tools: process_conversation_context()
  ‚îî‚îÄ‚îÄ Output: Suggestion (text, confidence)
  ```

  **AutonomousAgent (YOLO Mode)**:
  ```python
  AutonomousAgent (Single Agent, NOT multi-agent)
  ‚îú‚îÄ‚îÄ Model: Gemini 2.5 Flash
  ‚îú‚îÄ‚îÄ Tools:
  ‚îÇ   ‚îú‚îÄ‚îÄ track_goal_progress()
  ‚îÇ   ‚îú‚îÄ‚îÄ check_safety_constraints()
  ‚îÇ   ‚îî‚îÄ‚îÄ process_conversation_context()
  ‚îî‚îÄ‚îÄ Output: AutonomousResponse (action, response_text, updated_state)

  NOTE: Single agent with tools, no sub-agents or orchestration
  ```

**Step 0.3: Create Project Structure** - ‚úÖ COMPLETE
- Files created:
  ```bash
  ‚úÖ backend/app/agents/__init__.py
  ‚úÖ backend/app/agents/suggestion_agent.py
  ‚úÖ backend/app/agents/autonomous_agent.py
  ‚úÖ backend/app/agents/tools/__init__.py
  ‚úÖ backend/app/agents/tools/context_tools.py
  ‚úÖ backend/app/agents/tools/goal_tools.py
  ‚úÖ backend/app/agents/tools/safety_tools.py
  ‚úÖ backend/app/api/routes/__init__.py
  ‚úÖ backend/app/api/routes/suggest.py
  ‚úÖ backend/app/api/routes/autonomous.py
  ‚úÖ backend/app/api/routes/feedback.py
  ‚úÖ backend/app/api/routes/conversation_logs.py
  ‚úÖ backend/app/services/agent_service.py
  ```

#### **Phase 1: Core Backend with ADK (2-3 hours) - ‚úÖ COMPLETE**

**Step 1: Implement ADK Tool Functions** - ‚úÖ COMPLETE

**Step 1.1: Create conversation context tool** - ‚úÖ COMPLETE
- Files created: `backend/app/agents/tools/context_tools.py`
- Implementation status: ‚úÖ Fully implemented
  ```python
  from typing import List, Dict
  import re

  def process_conversation_context(messages: List[Dict]) -> Dict:
      """
      Process conversation context (ADK tool function)

      Args:
          messages: List of message dicts with role, content, timestamp

      Returns:
          Dict with processed_messages, intent, and extracted entities
      """
      if not messages or len(messages) > 50:
          return {"error": "Invalid message count"}

      processed = []
      entities = {"order_numbers": [], "emails": []}

      for msg in messages:
          content = msg.get("content", "").strip()
          processed.append({
              "role": msg.get("role"),
              "content": content,
              "timestamp": msg.get("timestamp")
          })

          # Extract entities
          entities["order_numbers"].extend(re.findall(r'#\d+', content))
          entities["emails"].extend(re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', content))

      # Detect intent
      all_content = " ".join([m["content"] for m in processed]).lower()
      intent = "general_inquiry"
      if any(w in all_content for w in ["order", "shipping", "delivery"]):
          intent = "order_inquiry"
      elif any(w in all_content for w in ["refund", "return", "cancel"]):
          intent = "refund_request"

      return {
          "processed_messages": processed,
          "intent": intent,
          "entities": entities
      }
  ```

**Step 1.2: Create goal tracking tool** - ‚úÖ COMPLETE
- Files created: `backend/app/agents/tools/goal_tools.py`
- Implementation status: ‚úÖ Fully implemented
  ```python
  from typing import Dict

  def track_goal_progress(goal: Dict, current_state: Dict, latest_action: str) -> Dict:
      """Track YOLO goal progress (ADK tool function)"""
      new_turn = current_state.get("current_turn", 0) + 1
      max_turns = goal.get("max_turns", 10)

      base_progress = min(new_turn / max_turns, 0.9)

      if "resolved" in latest_action.lower():
          progress = 1.0
      else:
          progress = base_progress

      return {
          "active": progress < 1.0 and new_turn < max_turns,
          "current_turn": new_turn,
          "progress": round(progress, 2)
      }
  ```

**Step 1.3: Create safety checking tool** - ‚úÖ COMPLETE
- Files created: `backend/app/agents/tools/safety_tools.py`
- Implementation status: ‚úÖ Fully implemented
  ```python
  from typing import Dict

  def check_safety_constraints(message: str, constraints: Dict, confidence: float) -> Dict:
      """Check safety constraints for escalation (ADK tool function)"""
      triggers = []
      message_lower = message.lower()

      # Check escalation keywords
      for keyword in constraints.get("escalation_keywords", []):
          if keyword.lower() in message_lower:
              triggers.append(f"escalation_keyword:{keyword}")

      # Check confidence threshold
      min_confidence = constraints.get("min_confidence", 0.7)
      if confidence < min_confidence:
          triggers.append(f"low_confidence:{confidence:.2f}")

      # Check confusion
      if constraints.get("stop_if_confused", True):
          if any(p in message_lower for p in ["i don't understand", "i'm not sure"]):
              triggers.append("confusion_detected")

      if triggers:
          return {
              "decision": "escalate",
              "reason": f"Safety violations: {', '.join(triggers)}",
              "triggers": triggers
          }
      else:
          return {
              "decision": "safe",
              "reason": "All checks passed",
              "triggers": []
          }
  ```

**Step 2: Implement SuggestionAgent (Single Agent)** - ‚úÖ COMPLETE
- Files created: `backend/app/agents/suggestion_agent.py`
- Implementation status: ‚úÖ Implemented with placeholder responses
- **TODO**: Replace placeholder with actual `agent.run()` call
  ```python
  from google.adk.agents import Agent
  from app.agents.tools.context_tools import process_conversation_context
  from app.models.request import SuggestRequest
  from app.models.response import Suggestion
  import os

  class SuggestionAgentService:
      """Single-agent service for Suggestion Mode (Gemini 2.5 Flash)"""

      def __init__(self, project_id: str, location: str):
          os.environ["GOOGLE_CLOUD_PROJECT"] = project_id
          os.environ["GOOGLE_CLOUD_REGION"] = location

          # Single agent with Gemini 2.5 Flash
          self.agent = Agent(
              name="suggestion_agent",
              model="gemini-2.5-flash",
              instruction="""You are an AI assistant helping customer support agents.
              Generate helpful, empathetic response suggestions.
              Maintain a professional yet friendly tone.""",
              description="Generates response suggestions for support agents",
              tools=[process_conversation_context]
          )

      async def generate_suggestion(self, request: SuggestRequest) -> Suggestion:
          """Generate suggestion with single ADK agent"""
          # Build prompt
          messages_text = "\n".join([
              f"{msg.role.upper()}: {msg.content}"
              for msg in request.conversation_context
          ])

          prefs = request.user_preferences or {}
          prompt = f"""Generate a {prefs.get('tone', 'professional')} customer support response.

Conversation:
{messages_text}

Requirements:
- Tone: {prefs.get('tone', 'professional')}
- Length: {prefs.get('length', 'medium')}
- Language: {prefs.get('language', 'en')}

Provide a helpful response."""

          # TODO: Actual ADK agent invocation
          # response = await self.agent.run(prompt)
          response_text = "[ADK Agent Response]"

          return Suggestion(
              text=response_text,
              confidence=0.85,
              reasoning="Generated with Gemini 2.5 Flash"
          )
  ```

**Step 3: Implement AutonomousAgent (Single Agent)** - ‚úÖ COMPLETE
- Files created: `backend/app/agents/autonomous_agent.py`
- Implementation status: ‚úÖ Implemented with placeholder responses
- **TODO**: Replace placeholder with actual `agent.run()` call
  ```python
  from google.adk.agents import Agent
  from app.agents.tools.goal_tools import track_goal_progress
  from app.agents.tools.safety_tools import check_safety_constraints
  from app.models.request import AutonomousRequest, GoalState
  from app.models.response import AutonomousResponse
  import os
  import time
  import uuid

  class AutonomousAgentService:
      """Single-agent service for YOLO Mode (Gemini 2.5 Flash)"""

      def __init__(self, project_id: str, location: str):
          os.environ["GOOGLE_CLOUD_PROJECT"] = project_id
          os.environ["GOOGLE_CLOUD_REGION"] = location

          # Single agent with Gemini 2.5 Flash and safety tools
          self.agent = Agent(
              name="autonomous_agent",
              model="gemini-2.5-flash",
              instruction="""You are an autonomous customer support agent.
              Analyze the goal, check safety constraints, and decide the next action.
              Use tools to track progress and validate safety before responding.""",
              description="Handles autonomous YOLO mode responses",
              tools=[track_goal_progress, check_safety_constraints]
          )

      async def process(self, request: AutonomousRequest) -> AutonomousResponse:
          """Process autonomous request with single agent"""
          # Build prompt with goal and safety context
          messages_text = "\n".join([
              f"{msg.role.upper()}: {msg.content}"
              for msg in request.conversation_context
          ])

          prompt = f"""Autonomous support task:

Goal: {request.goal.description} (Max turns: {request.goal.max_turns})
Current Turn: {request.goal_state.current_turn}/{request.goal.max_turns}
Progress: {request.goal_state.progress:.1%}

Safety Constraints:
- Min confidence: {request.safety_constraints.min_confidence}
- Escalation keywords: {', '.join(request.safety_constraints.escalation_keywords)}

Conversation:
{messages_text}

Decide: respond, escalate, or goal_complete"""

          # TODO: Actual ADK agent invocation with tool calls
          # The agent will:
          # 1. Call track_goal_progress() to update state
          # 2. Generate response
          # 3. Call check_safety_constraints() to validate
          # 4. Return action decision

          # Placeholder response
          return AutonomousResponse(
              action="respond",
              response_text="[ADK Agent Response]",
              updated_state=GoalState(
                  active=True,
                  current_turn=request.goal_state.current_turn + 1,
                  progress=min(request.goal_state.progress + 0.2, 1.0)
              ),
              reasoning="Decision based on goal and safety analysis",
              confidence=0.8,
              metadata={
                  "request_id": str(uuid.uuid4()),
                  "processing_time_ms": 1500,
                  "model_used": "gemini-2.5-flash",
                  "timestamp": int(time.time())
              }
          )
  ```

**Step 4: Create Unified Agent Service Layer** - ‚úÖ COMPLETE
- Files created: `backend/app/services/agent_service.py`
- Implementation status: ‚úÖ Fully implemented and tested
  ```python
  from app.core.config import settings
  from app.agents.suggestion_agent import SuggestionAgentService
  from app.agents.autonomous_agent import AutonomousAgentService

  class AgentService:
      """Unified service coordinating both ADK agents"""

      def __init__(self):
          self.suggestion_agent = SuggestionAgentService(
              project_id=settings.GCP_PROJECT_ID,
              location=settings.VERTEX_AI_LOCATION
          )

          self.autonomous_agent = AutonomousAgentService(
              project_id=settings.GCP_PROJECT_ID,
              location=settings.VERTEX_AI_LOCATION
          )

      async def generate_suggestion(self, request):
          return await self.suggestion_agent.generate_suggestion(request)

      async def generate_autonomous_response(self, request):
          return await self.autonomous_agent.process(request)
  ```

#### **Phase 2: API Endpoints (1-2 hours) - ‚úÖ COMPLETE**

**Step 5: Create Suggestion Mode API Endpoint** - ‚úÖ COMPLETE
- Files created: `backend/app/api/routes/suggest.py`
- Implementation status: ‚úÖ Fully implemented and tested
- Test result: ‚úÖ 200 OK - Returns suggestions with metadata
  ```python
  from fastapi import APIRouter, Depends, HTTPException
  from app.models.request import SuggestRequest
  from app.models.response import SuggestResponse, Metadata
  from app.services.agent_service import AgentService
  import time
  import uuid

  router = APIRouter()

  @router.post("/suggest-response", response_model=SuggestResponse)
  async def suggest_response(
      request: SuggestRequest,
      agent_service: AgentService = Depends()
  ):
      """Generate suggestion using single ADK agent"""
      start_time = time.time()

      try:
          suggestion = await agent_service.generate_suggestion(request)
          processing_time = int((time.time() - start_time) * 1000)

          return SuggestResponse(
              suggestions=[suggestion],
              metadata=Metadata(
                  request_id=str(uuid.uuid4()),
                  processing_time_ms=processing_time,
                  model_used="gemini-2.5-flash",
                  timestamp=int(time.time())
              )
          )
      except Exception as e:
          raise HTTPException(status_code=503, detail="AI service unavailable")
  ```

**Step 6: Create Autonomous Mode API Endpoint** - ‚úÖ COMPLETE
- Files created: `backend/app/api/routes/autonomous.py`
- Implementation status: ‚úÖ Fully implemented and tested
- Test result: ‚úÖ 200 OK - Returns action decision with updated state
  ```python
  from fastapi import APIRouter, Depends, HTTPException
  from app.models.request import AutonomousRequest
  from app.models.response import AutonomousResponse
  from app.services.agent_service import AgentService

  router = APIRouter()

  @router.post("/autonomous-response", response_model=AutonomousResponse)
  async def autonomous_response(
      request: AutonomousRequest,
      agent_service: AgentService = Depends()
  ):
      """Generate autonomous response using single ADK agent"""
      try:
          response = await agent_service.generate_autonomous_response(request)
          return response
      except Exception as e:
          raise HTTPException(status_code=503, detail="AI service unavailable")
  ```

**Step 7: Create Feedback and Logs Endpoints** - ‚úÖ COMPLETE
- Files created:
  - `backend/app/api/routes/feedback.py` - ‚úÖ Implemented
  - `backend/app/api/routes/conversation_logs.py` - ‚úÖ Implemented
- Implementation status:
  - Feedback endpoint: ‚úÖ Tested (200 OK)
  - Logs POST endpoint: ‚úÖ Tested (200 OK)
  - Logs GET endpoint: ‚úÖ Tested (200 OK) with pagination
- **TODO**: Replace in-memory storage with Firestore

**Step 8: Register Routes in Main App** - ‚úÖ COMPLETE
- Files modified: `backend/app/main.py`
- Implementation status: ‚úÖ All routes registered and working
- Routes added:
  - ‚úÖ `/api/suggest-response` (suggestions tag)
  - ‚úÖ `/api/autonomous-response` (autonomous tag)
  - ‚úÖ `/api/feedback` (feedback tag)
  - ‚úÖ `/api/conversation-logs` (logs tag)
  ```python
  from fastapi import FastAPI
  from fastapi.middleware.cors import CORSMiddleware
  from app.api.routes import suggest, autonomous, feedback, logs
  from app.core.config import settings

  app = FastAPI(title="Support Chat AI API")

  # CORS
  app.add_middleware(
      CORSMiddleware,
      allow_origins=settings.ALLOWED_ORIGINS,
      allow_credentials=True,
      allow_methods=["*"],
      allow_headers=["*"],
  )

  # Routes
  app.include_router(suggest.router, prefix="/api", tags=["suggestions"])
  app.include_router(autonomous.router, prefix="/api", tags=["autonomous"])
  app.include_router(feedback.router, prefix="/api", tags=["feedback"])
  app.include_router(logs.router, prefix="/api", tags=["logs"])

  @app.get("/health")
  async def health_check():
      return {"status": "healthy", "model": "gemini-2.5-flash"}
  ```

#### **Phase 3: Security & Infrastructure (1-2 hours) - ‚è≥ PENDING**

**Step 9: Implement API Key Authentication**
- Files to modify: `backend/app/core/security.py`
- Status: ‚ùå Not started
- Required: Middleware to validate X-API-Key header

**Step 10: Add Rate Limiting with SlowAPI**
- Files to modify: `backend/app/main.py`
- Status: ‚ùå Not started
- Required: SlowAPI middleware with 60 req/min limit

**Step 11: Implement Firestore Integration**
- Files to create: `backend/app/core/database.py`
- Status: ‚ùå Not started
- Required: Replace in-memory storage in feedback.py and conversation_logs.py

**Step 12: Set Up Secret Manager Integration**
- Files to modify: `backend/app/core/security.py`
- Status: ‚ùå Not started
- Required: Load API keys from GCP Secret Manager

#### **Phase 4: Extension Integration (1-2 hours) - ‚è≥ PENDING**

**Step 13: Replace Mock API Client**
- Files to modify: `extension/src/background/api-client.ts`
- Status: ‚ùå Not started
- Required: Remove mock-api.ts, add real HTTP calls to Cloud Run

**Step 14: Update TypeScript Types**
- Files to modify: `extension/src/types/api.ts`
- Status: ‚ùå Not started
- Required: Update types to match updated Pydantic models (Suggestion, Metadata changes)

**Step 15: Add Environment Configuration**
- Files to modify: `extension/.env`, `extension/vite.config.ts`
- Status: ‚ùå Not started
- Required: Add VITE_API_URL environment variable for Cloud Run URL

#### **Phase 5: Deployment (1-2 hours) - ‚è≥ PENDING**

**Step 16: Update Dockerfile** - ‚ö†Ô∏è NEEDS REVIEW
- Files to modify: `backend/Dockerfile`
- Changes needed:
  ```dockerfile
  FROM python:3.11-slim
  WORKDIR /app
  COPY requirements.txt .
  RUN pip install --no-cache-dir -r requirements.txt
  COPY ./app ./app
  CMD exec gunicorn app.main:app \
      --bind 0.0.0.0:8080 \
      --workers 1 \
      --threads 8 \
      --timeout 120 \
      --worker-class uvicorn.workers.UvicornWorker
  ```

**Step 17: Deploy to Cloud Run (Unified Service)** - ‚ùå NOT STARTED
- Terminal commands:
  ```bash
  export PROJECT_ID=your-project-id
  gcloud config set project $PROJECT_ID

  cd backend
  docker build -t us-central1-docker.pkg.dev/$PROJECT_ID/support-chat-ai/backend:v1.0.0 .
  docker push us-central1-docker.pkg.dev/$PROJECT_ID/support-chat-ai/backend:v1.0.0

  # Deploy unified service (FastAPI + ADK)
  gcloud run deploy support-chat-ai \
    --image=us-central1-docker.pkg.dev/$PROJECT_ID/support-chat-ai/backend:v1.0.0 \
    --region=us-central1 \
    --platform=managed \
    --allow-unauthenticated \
    --set-env-vars="GCP_PROJECT_ID=$PROJECT_ID,ENVIRONMENT=production,GEMINI_MODEL=gemini-2.5-flash" \
    --min-instances=1 \
    --max-instances=10 \
    --memory=2Gi \
    --cpu=2 \
    --timeout=120

  gcloud run services describe support-chat-ai \
    --region=us-central1 \
    --format='value(status.url)'
  ```

**Step 18: Configure GCP Secrets**
- Status: ‚ùå Not started
- Required: Create API key secret in Secret Manager

**Step 19: Update Extension with Production URL**
- Status: ‚ùå Not started
- Required: After deployment, update extension .env with Cloud Run URL

#### **Phase 6: Testing & Validation (2-3 hours) - ‚è≥ PENDING**

**Step 20: Write Unit Tests**
- Status: ‚ùå Not started
- Required: pytest tests for agents, tools, and services

**Step 21: Write Integration Tests**
- Status: ‚ùå Not started
- Required: pytest tests for API endpoints with TestClient

**Step 22: Validate OpenAPI Compliance**
- Status: ‚ùå Not started
- Required: Compare actual responses with `docs/api-spec.yaml`

**Step 23: End-to-End Testing with Extension**
- Status: ‚ùå Not started
- Required: Test full flow from extension ‚Üí backend ‚Üí AI response

**Step 24: Performance and Load Testing**
- Status: ‚ùå Not started
- Required: Measure latency (<2s target) and concurrent request handling

## üéØ Success Criteria

**Backend:**
- ‚úÖ All API endpoints return 2xx responses
- ‚úÖ All endpoints match OpenAPI spec exactly
- ‚úÖ **Google ADK successfully integrated** (simplified single-agent)
- ‚úÖ **Single SuggestionAgent with Gemini 2.5 Flash works**
- ‚úÖ **Single AutonomousAgent with Gemini 2.5 Flash works**
- ‚úÖ Response latency P95 < 2 seconds
- ‚úÖ Rate limiting prevents abuse (60 req/min)
- ‚úÖ **Unified Cloud Run deployment successful** (no Agent Engine)
- ‚úÖ Tests passing with 80%+ coverage

**Simplification Success:**
- ‚úÖ **Only Gemini 2.5 Flash used** (cost-effective)
- ‚úÖ **No multi-agent complexity** (single agent per mode)
- ‚úÖ **Single Cloud Run service** (FastAPI + ADK unified)
- ‚úÖ **Simpler codebase** (easier to maintain and debug)
- ‚úÖ **Lower costs** (Flash model + single deployment)

**Extension Integration:**
- ‚úÖ Extension successfully calls backend API
- ‚úÖ Real ADK-powered AI suggestions displayed
- ‚úÖ YOLO mode works with single-agent autonomous responses

**Security:**
- ‚úÖ API key authentication required
- ‚úÖ CORS restricted to extension origin
- ‚úÖ Rate limiting prevents DoS (60/min)

**Deployment:**
- ‚úÖ **Single Cloud Run service deployed** (unified architecture)
- ‚úÖ Auto-scaling configured (1-10 instances)
- ‚úÖ Environment variables configured
- ‚úÖ Monitoring enabled

## üîß How to Run Locally

**Start the Backend Server:**
```bash
cd backend
source venv/bin/activate  # Windows: venv\Scripts\activate
uvicorn app.main:app --reload --port 8001
```

**Access the API:**
- Swagger Docs: http://localhost:8001/docs
- Health Check: http://localhost:8001/health
- Root: http://localhost:8001/

**Run Test Scripts:**
```bash
cd backend
source venv/bin/activate
python test_api.py              # Test suggest and feedback endpoints
python test_autonomous_api.py   # Test autonomous and logs endpoints
```

**Test Results (2025-11-04):**
All endpoints returning 200 OK:
- ‚úÖ GET /health
- ‚úÖ GET /
- ‚úÖ POST /api/suggest-response
- ‚úÖ POST /api/autonomous-response
- ‚úÖ POST /api/feedback
- ‚úÖ POST /api/conversation-logs
- ‚úÖ GET /api/conversation-logs

## üìö Additional Notes

**Simplified Architecture Benefits:**
1. **Cost Savings**: Gemini 2.5 Flash is 10x cheaper than Pro
2. **Faster Development**: Single agent per mode = simpler code
3. **Easier Debugging**: No multi-agent orchestration complexity
4. **Better Performance**: Less overhead, faster responses
5. **Simpler Deployment**: One service, one deployment, easier rollbacks
6. **Good Enough**: Flash model handles support chat well

**Google ADK Resources:**
- **Official Docs**: https://google.github.io/adk-docs/
- **GitHub**: https://github.com/google/adk-python
- **Examples**: Agent examples and best practices

**Cost Optimization:**
- Gemini 2.5 Flash only (10x cheaper than Pro)
- Single Cloud Run service (no separate deployments)
- Response caching for common queries
- Auto-scaling prevents waste

**Monitoring:**
- Response latency < 2 seconds (target)
- Error rate < 5%
- CPU/Memory usage
- Agent execution times
- Model costs (Flash pricing)

**Future Enhancements:**
- Add streaming responses (ADK supports streaming)
- Response caching with Redis
- A/B testing different prompts
- Analytics dashboard
- Upgrade to Gemini Pro if Flash insufficient
